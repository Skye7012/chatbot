import streamlit as st
from PIL import Image
import numpy as np
import torch
from torchvision import transforms
from st_supabase_connection import SupabaseConnection

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üé® AI-–•—É–¥–æ–∂–Ω–∏–∫: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å—Ç–∏–ª–µ —Ö—É–¥–æ–∂–Ω–∏–∫–æ–≤")

# –í—ã–±–æ—Ä —Å—Ç–∏–ª—è
style = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å —Ö—É–¥–æ–∂–Ω–∏–∫–∞:",
    ("–í–∞–Ω –ì–æ–≥", "–ú—É–Ω–∫", "–ü–∏–∫–∞—Å—Å–æ", "–ú–æ–Ω–µ")
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–µ —Ñ–æ—Ç–æ:", type=["jpg", "jpeg"])


@st.cache_resource
def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å AnimeGANv2 –∏–∑ torchhub"""
    model = torch.hub.load('bryandlee/animegan2-pytorch', 'generator').eval()
    return model


def stylize_image(image, model):
    """–ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—é"""
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.ToTensor(),
    ])
    input_tensor = preprocess(image).unsqueeze(0)
    with torch.no_grad():
        output = model(input_tensor)
    output_image = output.squeeze().permute(1, 2, 0).numpy()
    output_image = np.clip(output_image, 0, 1)
    return (output_image * 255).astype(np.uint8)


# –ò—Å–ø–æ–ª—å–∑—É–µ–º session_state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'feedback_sent' not in st.session_state:
    st.session_state.feedback_sent = False

if uploaded_file is not None:
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = Image.open(uploaded_file)
    st.image(image, caption="–í–∞—à–µ —Ñ–æ—Ç–æ", use_container_width=True)

    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if not st.session_state.processed and st.button("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å—Ç–∏–ª—å " + style):
        st.session_state.processed = True
        st.session_state.feedback_sent = False

        st.write("‚è≥ –ò–¥—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
        try:
            model = load_model()
            st.session_state.stylized_image = stylize_image(image, model)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")
            st.warning("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
            st.session_state.processed = False

    if st.session_state.processed and 'stylized_image' in st.session_state:
        st.image(st.session_state.stylized_image,
                 caption=f"–°—Ç–∏–ª—å: {style}", use_container_width=True)

        # –§–æ—Ä–º–∞ –¥–ª—è –æ—Ç–∑—ã–≤–∞
        if not st.session_state.feedback_sent:
            st.subheader("–ü–æ–Ω—Ä–∞–≤–∏–ª—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç?")
            feedback = st.text_area("–û—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à –æ—Ç–∑—ã–≤ –æ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏:")

            if st.button('–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤'):
                if feedback:
                    try:
                        conn = st.connection(
                            "supabase", type=SupabaseConnection)
                        response = conn.table("Feedback").insert(
                            {"rating": 1, "comment": feedback}).execute()
                        st.success('–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–∑—ã–≤!')
                        st.session_state.feedback_sent = True
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–∑—ã–≤–∞: {e}")
                else:
                    st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ –æ—Ç–∑—ã–≤ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π")
